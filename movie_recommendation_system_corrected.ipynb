{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Movie Search API - Dataset Analysis & Recommendation System\n",
    "\n",
    "This notebook analyzes the movies dataset, tests the existing search implementation, and builds a recommendation system using content-based filtering and matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports for recommendation system\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, average_precision_score, roc_curve\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movies dataset...\n",
      "Dataset shape: (45466, 24)\n",
      "Columns: ['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id', 'imdb_id', 'original_language', 'original_title', 'overview', 'popularity', 'poster_path', 'production_companies', 'production_countries', 'release_date', 'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title', 'video', 'vote_average', 'vote_count']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the movie data\n",
    "print(\"Loading movies dataset...\")\n",
    "movies_df = pd.read_csv('movie_data/movies_metadata.csv', low_memory=False)\n",
    "\n",
    "print(f\"Dataset shape: {movies_df.shape}\")\n",
    "print(f\"Columns: {movies_df.columns.tolist()}\")\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "After cleaning: 22928 movies\n",
      "Date range: 1874.0 - 2020.0\n",
      "Average rating: 6.17\n",
      "Average runtime: 101 minutes\n"
     ]
    }
   ],
   "source": [
    "# Clean and process the data\n",
    "print(\"Cleaning data...\")\n",
    "\n",
    "# Convert release_date to datetime\n",
    "movies_df['release_date'] = pd.to_datetime(movies_df['release_date'], errors='coerce')\n",
    "movies_df['release_year'] = movies_df['release_date'].dt.year\n",
    "\n",
    "# Convert numeric columns\n",
    "movies_df['vote_average'] = pd.to_numeric(movies_df['vote_average'], errors='coerce')\n",
    "movies_df['vote_count'] = pd.to_numeric(movies_df['vote_count'], errors='coerce')\n",
    "movies_df['budget'] = pd.to_numeric(movies_df['budget'], errors='coerce')\n",
    "movies_df['revenue'] = pd.to_numeric(movies_df['revenue'], errors='coerce')\n",
    "movies_df['runtime'] = pd.to_numeric(movies_df['runtime'], errors='coerce')\n",
    "\n",
    "# Process genres\n",
    "def parse_genres(genres_str):\n",
    "    try:\n",
    "        if pd.isna(genres_str):\n",
    "            return []\n",
    "        genres_list = eval(genres_str)\n",
    "        return [genre['name'] for genre in genres_list]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "movies_df['genres_list'] = movies_df['genres'].apply(parse_genres)\n",
    "\n",
    "# Filter out movies with missing essential data\n",
    "movies_clean = movies_df.dropna(subset=['title', 'release_date', 'vote_average'])\n",
    "movies_clean = movies_clean[movies_clean['vote_count'] >= 10]  # At least 10 votes\n",
    "\n",
    "print(f\"After cleaning: {movies_clean.shape[0]} movies\")\n",
    "print(f\"Date range: {movies_clean['release_year'].min()} - {movies_clean['release_year'].max()}\")\n",
    "print(f\"Average rating: {movies_clean['vote_average'].mean():.2f}\")\n",
    "print(f\"Average runtime: {movies_clean['runtime'].mean():.0f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing Existing Search Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract genre from query text (from original app.py)\n",
    "def extract_genres(query):\n",
    "    genre_map = {\n",
    "        'horror': ['horror'],\n",
    "        'action': ['action'],\n",
    "        'comedy': ['comedy', 'romance'],\n",
    "        'drama': ['drama']\n",
    "    }\n",
    "    \n",
    "    words = query.lower().split()\n",
    "    possible_genres = []\n",
    "    for word in words:\n",
    "        if word in genre_map:\n",
    "            possible_genres.extend(genre_map[word])\n",
    "    return list(set(possible_genres))\n",
    "\n",
    "# Search function that mimics the Flask API endpoint\n",
    "def search_movies(query, movies_df):\n",
    "    if not query:\n",
    "        return {'error': 'Query is required'}\n",
    "    \n",
    "    target_genres = extract_genres(query)\n",
    "    \n",
    "    # Filter movies based on genres\n",
    "    results = []\n",
    "    for index, movie in movies_df.iterrows():\n",
    "        if movie['genres_list']:  # Use the parsed genres list\n",
    "            if any(genre.lower() in [tg.lower() for tg in target_genres] for genre in movie['genres_list']):\n",
    "                results.append({\n",
    "                    'title': movie['title'],\n",
    "                    'release_date': str(movie['release_date']),\n",
    "                    'rating': movie['vote_average']\n",
    "                })\n",
    "    \n",
    "    return {'results': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING EXISTING MOVIE SEARCH IMPLEMENTATION\n",
      "============================================================\n",
      "\n",
      "Query: 'A horror movie suitable for teenagers in the 12-15 age range'\n",
      "----------------------------------------\n",
      "Found 3208 results\n",
      "  1. Dracula: Dead and Loving It (1995-12-22) - Rating: 5.7\n",
      "  2. From Dusk Till Dawn (1996-01-19) - Rating: 6.9\n",
      "  3. Screamers (1995-09-08) - Rating: 6.1\n",
      "  ... and 3205 more results\n",
      "\n",
      "Query: 'A spooky movie suitable for teenagers in the 12-15 age range'\n",
      "----------------------------------------\n",
      "Found 0 results\n",
      "\n",
      "Query: 'War commandos'\n",
      "----------------------------------------\n",
      "Found 0 results\n",
      "\n",
      "Query: 'action movies'\n",
      "----------------------------------------\n",
      "Found 4338 results\n",
      "  1. Heat (1995-12-15) - Rating: 7.7\n",
      "  2. Tom and Huck (1995-12-22) - Rating: 5.4\n",
      "  3. Sudden Death (1995-12-22) - Rating: 5.5\n",
      "  ... and 4335 more results\n",
      "\n",
      "Query: 'comedy films'\n",
      "----------------------------------------\n",
      "Found 9537 results\n",
      "  1. Toy Story (1995-10-30) - Rating: 7.7\n",
      "  2. Grumpier Old Men (1995-12-22) - Rating: 6.5\n",
      "  3. Waiting to Exhale (1995-12-22) - Rating: 6.1\n",
      "  ... and 9534 more results\n",
      "\n",
      "Query: 'drama movies'\n",
      "----------------------------------------\n",
      "Found 10830 results\n",
      "  1. Waiting to Exhale (1995-12-22) - Rating: 6.1\n",
      "  2. Heat (1995-12-15) - Rating: 7.7\n",
      "  3. Tom and Huck (1995-12-22) - Rating: 5.4\n",
      "  ... and 10827 more results\n"
     ]
    }
   ],
   "source": [
    "# Test queries from the readme\n",
    "test_queries = [\n",
    "    \"A horror movie suitable for teenagers in the 12-15 age range\",\n",
    "    \"A spooky movie suitable for teenagers in the 12-15 age range\",\n",
    "    \"War commandos\",\n",
    "    \"action movies\",\n",
    "    \"comedy films\",\n",
    "    \"drama movies\"\n",
    "]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING EXISTING MOVIE SEARCH IMPLEMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    results = search_movies(query, movies_clean)\n",
    "    \n",
    "    if 'error' in results:\n",
    "        print(f\"Error: {results['error']}\")\n",
    "    else:\n",
    "        num_results = len(results['results'])\n",
    "        print(f\"Found {num_results} results\")\n",
    "        \n",
    "        # Show first 3 results\n",
    "        for i, movie in enumerate(results['results'][:3]):\n",
    "            release_date = movie['release_date'][:10] if movie['release_date'] != 'NaT' else 'Unknown'\n",
    "            print(f\"  {i+1}. {movie['title']} ({release_date}) - Rating: {movie['rating']}\")\n",
    "        \n",
    "        if num_results > 3:\n",
    "            print(f\"  ... and {num_results - 3} more results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Additional Data for Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading additional datasets...\n",
      "Credits dataset shape: (45476, 3)\n",
      "Keywords dataset shape: (46419, 2)\n",
      "Ratings dataset shape: (100004, 4)\n",
      "\n",
      "Dataset previews:\n",
      "\n",
      "Credits columns: ['cast', 'crew', 'id']\n",
      "Keywords columns: ['id', 'keywords']\n",
      "Ratings columns: ['userId', 'movieId', 'rating', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "# Load additional datasets for recommendation system\n",
    "print(\"Loading additional datasets...\")\n",
    "\n",
    "# Load credits data (cast and crew information)\n",
    "credits_df = pd.read_csv('movie_data/credits.csv')\n",
    "print(f\"Credits dataset shape: {credits_df.shape}\")\n",
    "\n",
    "# Load keywords data  \n",
    "keywords_df = pd.read_csv('movie_data/keywords.csv')\n",
    "print(f\"Keywords dataset shape: {keywords_df.shape}\")\n",
    "\n",
    "# Load ratings data\n",
    "ratings_df = pd.read_csv('movie_data/ratings_small.csv')  # Using small version for performance\n",
    "print(f\"Ratings dataset shape: {ratings_df.shape}\")\n",
    "\n",
    "print(\"\\nDataset previews:\")\n",
    "print(\"\\nCredits columns:\", credits_df.columns.tolist())\n",
    "print(\"Keywords columns:\", keywords_df.columns.tolist())\n",
    "print(\"Ratings columns:\", ratings_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing additional data...\n",
      "Fixing data types for merging...\n",
      "After type conversion:\n",
      "Movies ID type: int64\n",
      "Credits ID type: int64\n",
      "Keywords ID type: int64\n",
      "Merging datasets...\n",
      "Enhanced movies dataset shape: (23371, 29)\n",
      "Sample enhanced movie data:\n",
      "Title: Toy Story\n",
      "Genres: ['Animation', 'Comedy', 'Family']\n",
      "Cast: []\n",
      "Director: \n",
      "Keywords: ['jealousy', 'toy', 'boy', 'friendship', 'friends']\n"
     ]
    }
   ],
   "source": [
    "# Process and merge the datasets\n",
    "import json\n",
    "\n",
    "def parse_json_field(x):\n",
    "    \"\"\"Parse JSON-like fields safely\"\"\"\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return []\n",
    "        # Replace single quotes with double quotes for valid JSON\n",
    "        json_str = str(x).replace(\"'\", '\"')\n",
    "        data = json.loads(json_str)\n",
    "        if isinstance(data, list):\n",
    "            return [item.get('name', '') for item in data if isinstance(item, dict)]\n",
    "        return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def get_top_cast(cast_str, n=5):\n",
    "    \"\"\"Extract top N cast members\"\"\"\n",
    "    try:\n",
    "        if pd.isna(cast_str):\n",
    "            return []\n",
    "        # Replace single quotes with double quotes for valid JSON\n",
    "        json_str = str(cast_str).replace(\"'\", '\"')\n",
    "        cast_list = json.loads(json_str)\n",
    "        return [actor['name'] for actor in cast_list[:n]]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def get_director(crew_str):\n",
    "    \"\"\"Extract director from crew data\"\"\"\n",
    "    try:\n",
    "        if pd.isna(crew_str):\n",
    "            return ''\n",
    "        # Replace single quotes with double quotes for valid JSON\n",
    "        json_str = str(crew_str).replace(\"'\", '\"')\n",
    "        crew_list = json.loads(json_str)\n",
    "        for person in crew_list:\n",
    "            if person.get('job') == 'Director':\n",
    "                return person.get('name', '')\n",
    "        return ''\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "print(\"Processing additional data...\")\n",
    "\n",
    "# Process credits data\n",
    "credits_df['cast_list'] = credits_df['cast'].apply(lambda x: get_top_cast(x, 5))\n",
    "credits_df['director'] = credits_df['crew'].apply(get_director)\n",
    "\n",
    "# Process keywords data\n",
    "keywords_df['keywords_list'] = keywords_df['keywords'].apply(parse_json_field)\n",
    "\n",
    "# Fix data type mismatches before merging\n",
    "print(\"Fixing data types for merging...\")\n",
    "\n",
    "# Convert id columns to consistent integer type\n",
    "movies_clean = movies_clean.copy()\n",
    "movies_clean['id'] = pd.to_numeric(movies_clean['id'], errors='coerce')\n",
    "credits_df['id'] = pd.to_numeric(credits_df['id'], errors='coerce')\n",
    "keywords_df['id'] = pd.to_numeric(keywords_df['id'], errors='coerce')\n",
    "\n",
    "# Remove rows with invalid IDs\n",
    "movies_clean = movies_clean.dropna(subset=['id'])\n",
    "credits_df = credits_df.dropna(subset=['id'])\n",
    "keywords_df = keywords_df.dropna(subset=['id'])\n",
    "\n",
    "# Convert to int\n",
    "movies_clean['id'] = movies_clean['id'].astype(int)\n",
    "credits_df['id'] = credits_df['id'].astype(int)\n",
    "keywords_df['id'] = keywords_df['id'].astype(int)\n",
    "\n",
    "print(f\"After type conversion:\")\n",
    "print(f\"Movies ID type: {movies_clean['id'].dtype}\")\n",
    "print(f\"Credits ID type: {credits_df['id'].dtype}\")\n",
    "print(f\"Keywords ID type: {keywords_df['id'].dtype}\")\n",
    "\n",
    "# Merge all datasets\n",
    "print(\"Merging datasets...\")\n",
    "movies_enhanced = movies_clean.merge(credits_df[['id', 'cast_list', 'director']], on='id', how='left')\n",
    "movies_enhanced = movies_enhanced.merge(keywords_df[['id', 'keywords_list']], on='id', how='left')\n",
    "\n",
    "# Fill NaN values\n",
    "movies_enhanced['cast_list'] = movies_enhanced['cast_list'].fillna('').apply(lambda x: x if isinstance(x, list) else [])\n",
    "movies_enhanced['keywords_list'] = movies_enhanced['keywords_list'].fillna('').apply(lambda x: x if isinstance(x, list) else [])\n",
    "movies_enhanced['director'] = movies_enhanced['director'].fillna('')\n",
    "movies_enhanced['overview'] = movies_enhanced['overview'].fillna('')\n",
    "\n",
    "print(f\"Enhanced movies dataset shape: {movies_enhanced.shape}\")\n",
    "print(f\"Sample enhanced movie data:\")\n",
    "sample_movie = movies_enhanced.iloc[0]\n",
    "print(f\"Title: {sample_movie['title']}\")\n",
    "print(f\"Genres: {sample_movie['genres_list']}\")\n",
    "print(f\"Cast: {sample_movie['cast_list']}\")\n",
    "print(f\"Director: {sample_movie['director']}\")\n",
    "print(f\"Keywords: {sample_movie['keywords_list'][:5]}\")  # Show first 5 keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Content-Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUILDING CONTENT-BASED RECOMMENDATION SYSTEM\n",
      "============================================================\n",
      "Preparing content features...\n",
      "Prepared content features for 23371 movies\n",
      "Building TF-IDF content matrix...\n",
      "Content matrix shape: (23371, 10000)\n"
     ]
    }
   ],
   "source": [
    "class ContentBasedRecommender:\n",
    "    def __init__(self, movies_df):\n",
    "        self.movies_df = movies_df.copy()\n",
    "        self.tfidf_vectorizer = None\n",
    "        self.content_matrix = None\n",
    "        self.movie_indices = None\n",
    "        self._prepare_content_features()\n",
    "        self._build_content_matrix()\n",
    "    \n",
    "    def _prepare_content_features(self):\n",
    "        \"\"\"Combine all content features into a single text representation\"\"\"\n",
    "        print(\"Preparing content features...\")\n",
    "        \n",
    "        def clean_text(text):\n",
    "            if isinstance(text, list):\n",
    "                return ' '.join([str(item).lower().replace(' ', '') for item in text])\n",
    "            return str(text).lower().replace(' ', '') if text else ''\n",
    "        \n",
    "        # Prepare content features\n",
    "        self.movies_df['content_features'] = (\n",
    "            self.movies_df['genres_list'].apply(clean_text) + ' ' +\n",
    "            self.movies_df['keywords_list'].apply(clean_text) + ' ' +\n",
    "            self.movies_df['cast_list'].apply(clean_text) + ' ' +\n",
    "            self.movies_df['director'].apply(clean_text) + ' ' +\n",
    "            self.movies_df['overview'].fillna('').str.lower()\n",
    "        )\n",
    "        \n",
    "        # Create mapping from movie title to index\n",
    "        self.movie_indices = pd.Series(self.movies_df.index, index=self.movies_df['title']).to_dict()\n",
    "        \n",
    "        print(f\"Prepared content features for {len(self.movies_df)} movies\")\n",
    "    \n",
    "    def _build_content_matrix(self):\n",
    "        \"\"\"Build TF-IDF matrix from content features\"\"\"\n",
    "        print(\"Building TF-IDF content matrix...\")\n",
    "        \n",
    "        # Use TF-IDF to vectorize content features\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_features=10000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            max_df=0.8\n",
    "        )\n",
    "        \n",
    "        self.content_matrix = self.tfidf_vectorizer.fit_transform(self.movies_df['content_features'])\n",
    "        print(f\"Content matrix shape: {self.content_matrix.shape}\")\n",
    "    \n",
    "    def get_recommendations(self, movie_title, n_recommendations=10):\n",
    "        \"\"\"Get content-based recommendations for a movie\"\"\"\n",
    "        if movie_title not in self.movie_indices:\n",
    "            return f\"Movie '{movie_title}' not found in database\"\n",
    "        \n",
    "        # Get movie index\n",
    "        movie_idx = self.movie_indices[movie_title]\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        movie_vector = self.content_matrix[movie_idx]\n",
    "        similarities = cosine_similarity(movie_vector, self.content_matrix).flatten()\n",
    "        \n",
    "        # Get top similar movies (excluding the movie itself)\n",
    "        similar_indices = similarities.argsort()[::-1][1:n_recommendations+1]\n",
    "        \n",
    "        # Prepare recommendations\n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            movie = self.movies_df.iloc[idx]\n",
    "            recommendations.append({\n",
    "                'title': movie['title'],\n",
    "                'genres': movie['genres_list'],\n",
    "                'rating': movie['vote_average'],\n",
    "                'year': int(movie['release_year']) if pd.notna(movie['release_year']) else 'Unknown',\n",
    "                'similarity_score': similarities[idx],\n",
    "                'director': movie['director'],\n",
    "                'cast': movie['cast_list'][:3]  # Top 3 cast members\n",
    "            })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def get_recommendations_by_query(self, query, n_recommendations=10):\n",
    "        \"\"\"Get recommendations based on a text query\"\"\"\n",
    "        print(f\"Getting content-based recommendations for query: '{query}'\")\n",
    "        \n",
    "        # Transform query using the same TF-IDF vectorizer\n",
    "        query_vector = self.tfidf_vectorizer.transform([query.lower()])\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = cosine_similarity(query_vector, self.content_matrix).flatten()\n",
    "        \n",
    "        # Get top similar movies\n",
    "        similar_indices = similarities.argsort()[::-1][:n_recommendations]\n",
    "        \n",
    "        # Prepare recommendations\n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            if similarities[idx] > 0:  # Only include movies with positive similarity\n",
    "                movie = self.movies_df.iloc[idx]\n",
    "                recommendations.append({\n",
    "                    'title': movie['title'],\n",
    "                    'genres': movie['genres_list'],\n",
    "                    'rating': movie['vote_average'],\n",
    "                    'year': int(movie['release_year']) if pd.notna(movie['release_year']) else 'Unknown',\n",
    "                    'similarity_score': similarities[idx],\n",
    "                    'director': movie['director'],\n",
    "                    'overview': movie['overview'][:100] + '...' if len(movie['overview']) > 100 else movie['overview']\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Initialize content-based recommender\n",
    "print(\"=\"*60)\n",
    "print(\"BUILDING CONTENT-BASED RECOMMENDATION SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "content_recommender = ContentBasedRecommender(movies_enhanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Content-Based Recommendations\n",
      "==================================================\n",
      "\n",
      "Recommendations similar to 'Toy Story':\n",
      "----------------------------------------\n",
      "1. Toy Story 3 (2010) - Rating: 7.6\n",
      "   Genres: Animation, Family, Comedy\n",
      "   Similarity: 0.492\n",
      "\n",
      "2. Toy Story 2 (1999) - Rating: 7.3\n",
      "   Genres: Animation, Comedy, Family\n",
      "   Similarity: 0.478\n",
      "\n",
      "3. Small Fry (2011) - Rating: 6.8\n",
      "   Genres: Animation, Family\n",
      "   Similarity: 0.321\n",
      "\n",
      "4. The 40 Year Old Virgin (2005) - Rating: 6.2\n",
      "   Genres: Comedy, Romance\n",
      "   Similarity: 0.298\n",
      "\n",
      "5. The Champ (1931) - Rating: 6.8\n",
      "   Genres: Drama\n",
      "   Similarity: 0.287\n",
      "\n",
      "\n",
      "Content-based results for: 'horror movie suitable for teenagers'\n",
      "----------------------------------------\n",
      "Getting content-based recommendations for query: 'horror movie suitable for teenagers'\n",
      "1. Diary of the Dead (2007) - Rating: 5.4\n",
      "   Similarity: 0.365\n",
      "2. Anguish (1987) - Rating: 6.6\n",
      "   Similarity: 0.331\n",
      "3. Madhouse (1974) - Rating: 6.0\n",
      "   Similarity: 0.322\n",
      "\n",
      "\n",
      "Content-based results for: 'spooky scary thriller'\n",
      "----------------------------------------\n",
      "Getting content-based recommendations for query: 'spooky scary thriller'\n",
      "1. Spooky Buddies (2011) - Rating: 4.8\n",
      "   Similarity: 0.267\n",
      "2. Campfire Tales (1997) - Rating: 6.1\n",
      "   Similarity: 0.243\n",
      "3. The Haunted Castle (1897) - Rating: 5.6\n",
      "   Similarity: 0.240\n",
      "\n",
      "\n",
      "Content-based results for: 'action adventure'\n",
      "----------------------------------------\n",
      "Getting content-based recommendations for query: 'action adventure'\n",
      "1. Alex L'ariete (2000) - Rating: 2.3\n",
      "   Similarity: 0.634\n",
      "2. Silver Medalist (2009) - Rating: 7.4\n",
      "   Similarity: 0.523\n",
      "3. Shadowboxing (2005) - Rating: 5.0\n",
      "   Similarity: 0.444\n",
      "\n",
      "\n",
      "Content-based results for: 'romantic comedy'\n",
      "----------------------------------------\n",
      "Getting content-based recommendations for query: 'romantic comedy'\n",
      "1. Sex, Love & Therapy (2014) - Rating: 4.9\n",
      "   Similarity: 0.536\n",
      "2. Letters to Santa (2011) - Rating: 7.1\n",
      "   Similarity: 0.445\n",
      "3. Tired of Kissing Frogs (2006) - Rating: 6.2\n",
      "   Similarity: 0.440\n",
      "\n",
      "\n",
      "Content-based results for: 'war military'\n",
      "----------------------------------------\n",
      "Getting content-based recommendations for query: 'war military'\n",
      "1. Never So Few (1959) - Rating: 6.1\n",
      "   Similarity: 0.384\n",
      "2. Taking Chance (2009) - Rating: 6.8\n",
      "   Similarity: 0.369\n",
      "3. Kamchatka (2002) - Rating: 6.3\n",
      "   Similarity: 0.347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test content-based recommendations\n",
    "print(\"Testing Content-Based Recommendations\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test with specific movie\n",
    "test_movie = \"Toy Story\"\n",
    "print(f\"\\nRecommendations similar to '{test_movie}':\")\n",
    "print(\"-\" * 40)\n",
    "recs = content_recommender.get_recommendations(test_movie, 5)\n",
    "for i, rec in enumerate(recs, 1):\n",
    "    print(f\"{i}. {rec['title']} ({rec['year']}) - Rating: {rec['rating']:.1f}\")\n",
    "    print(f\"   Genres: {', '.join(rec['genres'][:3])}\")\n",
    "    print(f\"   Similarity: {rec['similarity_score']:.3f}\")\n",
    "    print()\n",
    "\n",
    "# Test with text queries from the original search\n",
    "test_queries = [\n",
    "    \"horror movie suitable for teenagers\",\n",
    "    \"spooky scary thriller\",\n",
    "    \"action adventure\",\n",
    "    \"romantic comedy\",\n",
    "    \"war military\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nContent-based results for: '{query}'\")\n",
    "    print(\"-\" * 40)\n",
    "    recs = content_recommender.get_recommendations_by_query(query, 3)\n",
    "    if recs:\n",
    "        for i, rec in enumerate(recs, 1):\n",
    "            print(f\"{i}. {rec['title']} ({rec['year']}) - Rating: {rec['rating']:.1f}\")\n",
    "            print(f\"   Similarity: {rec['similarity_score']:.3f}\")\n",
    "    else:\n",
    "        print(\"No recommendations found\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Collaborative Filtering Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing ratings data for collaborative filtering...\n",
      "Ratings dataset shape: (100004, 4)\n",
      "Unique users: 671\n",
      "Unique movies: 9066\n",
      "Rating range: 0.5 - 5.0\n",
      "\n",
      "Dataset overlap:\n",
      "Movies in ratings: 9066\n",
      "Movies in metadata: 22912\n",
      "Common movies: 2189\n",
      "Filtered ratings shape: (40008, 4)\n",
      "Creating user-item rating matrix...\n",
      "User-item matrix shape: (671, 2189)\n",
      "Sparsity: 0.973\n"
     ]
    }
   ],
   "source": [
    "# Prepare ratings data for collaborative filtering\n",
    "print(\"Preparing ratings data for collaborative filtering...\")\n",
    "print(f\"Ratings dataset shape: {ratings_df.shape}\")\n",
    "print(f\"Unique users: {ratings_df['userId'].nunique()}\")\n",
    "print(f\"Unique movies: {ratings_df['movieId'].nunique()}\")\n",
    "print(f\"Rating range: {ratings_df['rating'].min()} - {ratings_df['rating'].max()}\")\n",
    "\n",
    "# Check overlap between ratings and movies datasets\n",
    "ratings_movie_ids = set(ratings_df['movieId'].unique())\n",
    "movies_movie_ids = set(movies_enhanced['id'].astype(str).astype(int).unique())\n",
    "common_movies = ratings_movie_ids.intersection(movies_movie_ids)\n",
    "\n",
    "print(f\"\\nDataset overlap:\")\n",
    "print(f\"Movies in ratings: {len(ratings_movie_ids)}\")\n",
    "print(f\"Movies in metadata: {len(movies_movie_ids)}\")\n",
    "print(f\"Common movies: {len(common_movies)}\")\n",
    "\n",
    "# Filter ratings to only include movies we have metadata for\n",
    "ratings_filtered = ratings_df[ratings_df['movieId'].isin(common_movies)].copy()\n",
    "print(f\"Filtered ratings shape: {ratings_filtered.shape}\")\n",
    "\n",
    "# Create user-item matrix\n",
    "print(\"Creating user-item rating matrix...\")\n",
    "user_item_matrix = ratings_filtered.pivot_table(\n",
    "    index='userId', \n",
    "    columns='movieId', \n",
    "    values='rating'\n",
    ").fillna(0)\n",
    "\n",
    "print(f\"User-item matrix shape: {user_item_matrix.shape}\")\n",
    "print(f\"Sparsity: {(user_item_matrix == 0).sum().sum() / (user_item_matrix.shape[0] * user_item_matrix.shape[1]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUILDING COLLABORATIVE FILTERING RECOMMENDATION SYSTEM\n",
      "============================================================\n",
      "Building SVD model for collaborative filtering...\n",
      "SVD model built with 50 components\n",
      "Explained variance ratio: 0.557\n"
     ]
    }
   ],
   "source": [
    "class CollaborativeFilteringRecommender:\n",
    "    def __init__(self, user_item_matrix, movies_df, ratings_df):\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.movies_df = movies_df\n",
    "        self.ratings_df = ratings_df\n",
    "        self.svd_model = None\n",
    "        self.movie_id_to_title = {}\n",
    "        self.title_to_movie_id = {}\n",
    "        self._prepare_mappings()\n",
    "        self._build_model()\n",
    "    \n",
    "    def _prepare_mappings(self):\n",
    "        \"\"\"Create mappings between movie IDs and titles\"\"\"\n",
    "        # Create movie ID to title mapping\n",
    "        for _, movie in self.movies_df.iterrows():\n",
    "            movie_id = int(movie['id'])\n",
    "            if movie_id in self.user_item_matrix.columns:\n",
    "                self.movie_id_to_title[movie_id] = movie['title']\n",
    "                self.title_to_movie_id[movie['title']] = movie_id\n",
    "    \n",
    "    def _build_model(self):\n",
    "        \"\"\"Build SVD model for collaborative filtering\"\"\"\n",
    "        print(\"Building SVD model for collaborative filtering...\")\n",
    "        \n",
    "        # Convert to sparse matrix for efficiency\n",
    "        sparse_matrix = csr_matrix(self.user_item_matrix.values)\n",
    "        \n",
    "        # Use SVD for matrix factorization\n",
    "        self.svd_model = TruncatedSVD(n_components=50, random_state=42)\n",
    "        self.user_factors = self.svd_model.fit_transform(sparse_matrix)\n",
    "        self.item_factors = self.svd_model.components_.T\n",
    "        \n",
    "        print(f\"SVD model built with {self.svd_model.n_components} components\")\n",
    "        print(f\"Explained variance ratio: {self.svd_model.explained_variance_ratio_.sum():.3f}\")\n",
    "    \n",
    "    def get_movie_recommendations_by_title(self, movie_title, n_recommendations=10):\n",
    "        \"\"\"Get collaborative filtering recommendations for a movie title\"\"\"\n",
    "        if movie_title not in self.title_to_movie_id:\n",
    "            return f\"Movie '{movie_title}' not found in ratings data\"\n",
    "        \n",
    "        movie_id = self.title_to_movie_id[movie_title]\n",
    "        \n",
    "        # Get movie index in the matrix\n",
    "        movie_idx = list(self.user_item_matrix.columns).index(movie_id)\n",
    "        \n",
    "        # Calculate item-item similarity using the factorized matrices\n",
    "        movie_vector = self.item_factors[movie_idx].reshape(1, -1)\n",
    "        similarities = cosine_similarity(movie_vector, self.item_factors).flatten()\n",
    "        \n",
    "        # Get top similar movies\n",
    "        similar_indices = similarities.argsort()[::-1][1:n_recommendations+1]\n",
    "        \n",
    "        recommendations = []\n",
    "        for idx in similar_indices:\n",
    "            similar_movie_id = self.user_item_matrix.columns[idx]\n",
    "            if similar_movie_id in self.movie_id_to_title:\n",
    "                # Get movie details\n",
    "                movie_info = self.movies_df[self.movies_df['id'] == similar_movie_id].iloc[0]\n",
    "                \n",
    "                # Calculate average rating from ratings data\n",
    "                avg_rating = self.ratings_df[self.ratings_df['movieId'] == similar_movie_id]['rating'].mean()\n",
    "                \n",
    "                recommendations.append({\n",
    "                    'title': self.movie_id_to_title[similar_movie_id],\n",
    "                    'movie_id': similar_movie_id,\n",
    "                    'similarity_score': similarities[idx],\n",
    "                    'avg_rating': avg_rating,\n",
    "                    'genres': movie_info['genres_list'],\n",
    "                    'year': int(movie_info['release_year']) if pd.notna(movie_info['release_year']) else 'Unknown'\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def get_popular_movies(self, n_recommendations=10):\n",
    "        \"\"\"Get popular movies based on collaborative filtering data\"\"\"\n",
    "        # Calculate popularity score (average rating * number of ratings)\n",
    "        movie_stats = self.ratings_df.groupby('movieId').agg({\n",
    "            'rating': ['mean', 'count']\n",
    "        }).round(2)\n",
    "        \n",
    "        movie_stats.columns = ['avg_rating', 'num_ratings']\n",
    "        movie_stats = movie_stats.reset_index()\n",
    "        \n",
    "        # Filter movies with at least 50 ratings\n",
    "        popular_movies = movie_stats[movie_stats['num_ratings'] >= 50].copy()\n",
    "        popular_movies['popularity_score'] = popular_movies['avg_rating'] * np.log(popular_movies['num_ratings'])\n",
    "        popular_movies = popular_movies.sort_values('popularity_score', ascending=False)\n",
    "        \n",
    "        recommendations = []\n",
    "        for _, movie_stat in popular_movies.head(n_recommendations).iterrows():\n",
    "            movie_id = movie_stat['movieId']\n",
    "            if movie_id in self.movie_id_to_title:\n",
    "                movie_info = self.movies_df[self.movies_df['id'] == movie_id].iloc[0]\n",
    "                recommendations.append({\n",
    "                    'title': self.movie_id_to_title[movie_id],\n",
    "                    'movie_id': movie_id,\n",
    "                    'avg_rating': movie_stat['avg_rating'],\n",
    "                    'num_ratings': movie_stat['num_ratings'],\n",
    "                    'popularity_score': movie_stat['popularity_score'],\n",
    "                    'genres': movie_info['genres_list'],\n",
    "                    'year': int(movie_info['release_year']) if pd.notna(movie_info['release_year']) else 'Unknown'\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "# Initialize collaborative filtering recommender\n",
    "print(\"=\"*60)\n",
    "print(\"BUILDING COLLABORATIVE FILTERING RECOMMENDATION SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "collab_recommender = CollaborativeFilteringRecommender(user_item_matrix, movies_enhanced, ratings_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hybrid Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BUILDING HYBRID RECOMMENDATION SYSTEM\n",
      "============================================================\n",
      "Hybrid recommender initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "class HybridRecommender:\n",
    "    def __init__(self, content_recommender, collab_recommender, movies_df):\n",
    "        self.content_recommender = content_recommender\n",
    "        self.collab_recommender = collab_recommender\n",
    "        self.movies_df = movies_df\n",
    "        \n",
    "    def get_hybrid_recommendations(self, movie_title, n_recommendations=10, \n",
    "                                 content_weight=0.6, collab_weight=0.4):\n",
    "        \"\"\"Get hybrid recommendations combining content-based and collaborative filtering\"\"\"\n",
    "        print(f\"Getting hybrid recommendations for '{movie_title}'\")\n",
    "        print(f\"Weights: Content-based={content_weight}, Collaborative={collab_weight}\")\n",
    "        \n",
    "        # Get recommendations from both methods\n",
    "        content_recs = self.content_recommender.get_recommendations(movie_title, n_recommendations*2)\n",
    "        collab_recs = self.collab_recommender.get_movie_recommendations_by_title(movie_title, n_recommendations*2)\n",
    "        \n",
    "        if isinstance(content_recs, str) or isinstance(collab_recs, str):\n",
    "            # If one method fails, use the other\n",
    "            if isinstance(content_recs, str) and not isinstance(collab_recs, str):\n",
    "                print(\"Content-based failed, using collaborative filtering only\")\n",
    "                return collab_recs[:n_recommendations]\n",
    "            elif isinstance(collab_recs, str) and not isinstance(content_recs, str):\n",
    "                print(\"Collaborative filtering failed, using content-based only\")\n",
    "                return content_recs[:n_recommendations]\n",
    "            else:\n",
    "                return f\"Both methods failed for movie '{movie_title}'\"\n",
    "        \n",
    "        # Create a dictionary to combine scores\n",
    "        combined_scores = {}\n",
    "        \n",
    "        # Add content-based recommendations\n",
    "        for rec in content_recs:\n",
    "            title = rec['title']\n",
    "            combined_scores[title] = {\n",
    "                'title': title,\n",
    "                'content_score': rec['similarity_score'] * content_weight,\n",
    "                'collab_score': 0,\n",
    "                'genres': rec['genres'],\n",
    "                'rating': rec['rating'],\n",
    "                'year': rec['year']\n",
    "            }\n",
    "        \n",
    "        # Add collaborative filtering recommendations\n",
    "        for rec in collab_recs:\n",
    "            title = rec['title']\n",
    "            if title in combined_scores:\n",
    "                combined_scores[title]['collab_score'] = rec['similarity_score'] * collab_weight\n",
    "            else:\n",
    "                combined_scores[title] = {\n",
    "                    'title': title,\n",
    "                    'content_score': 0,\n",
    "                    'collab_score': rec['similarity_score'] * collab_weight,\n",
    "                    'genres': rec['genres'],\n",
    "                    'rating': rec['avg_rating'],\n",
    "                    'year': rec['year']\n",
    "                }\n",
    "        \n",
    "        # Calculate combined scores\n",
    "        for title in combined_scores:\n",
    "            combined_scores[title]['hybrid_score'] = (\n",
    "                combined_scores[title]['content_score'] + \n",
    "                combined_scores[title]['collab_score']\n",
    "            )\n",
    "        \n",
    "        # Sort by hybrid score\n",
    "        sorted_recs = sorted(combined_scores.values(), \n",
    "                           key=lambda x: x['hybrid_score'], reverse=True)\n",
    "        \n",
    "        return sorted_recs[:n_recommendations]\n",
    "    \n",
    "    def get_hybrid_query_recommendations(self, query, n_recommendations=10):\n",
    "        \"\"\"Get hybrid recommendations for a text query\"\"\"\n",
    "        print(f\"Getting hybrid recommendations for query: '{query}'\")\n",
    "        \n",
    "        # Get content-based recommendations for the query\n",
    "        content_recs = self.content_recommender.get_recommendations_by_query(query, n_recommendations*2)\n",
    "        \n",
    "        # Get popular movies as baseline\n",
    "        popular_recs = self.collab_recommender.get_popular_movies(n_recommendations*2)\n",
    "        \n",
    "        # Combine recommendations with content-based having higher weight for queries\n",
    "        combined_scores = {}\n",
    "        \n",
    "        # Add content-based recommendations (70% weight)\n",
    "        for rec in content_recs:\n",
    "            title = rec['title']\n",
    "            combined_scores[title] = {\n",
    "                'title': title,\n",
    "                'content_score': rec['similarity_score'] * 0.7,\n",
    "                'popularity_score': 0,\n",
    "                'genres': rec['genres'],\n",
    "                'rating': rec['rating'],\n",
    "                'year': rec['year']\n",
    "            }\n",
    "        \n",
    "        # Add popularity scores (30% weight)\n",
    "        for rec in popular_recs:\n",
    "            title = rec['title']\n",
    "            norm_popularity = min(rec['popularity_score'] / 100, 1.0)\n",
    "            \n",
    "            if title in combined_scores:\n",
    "                combined_scores[title]['popularity_score'] = norm_popularity * 0.3\n",
    "            else:\n",
    "                combined_scores[title] = {\n",
    "                    'title': title,\n",
    "                    'content_score': 0,\n",
    "                    'popularity_score': norm_popularity * 0.3,\n",
    "                    'genres': rec['genres'],\n",
    "                    'rating': rec['avg_rating'],\n",
    "                    'year': rec['year']\n",
    "                }\n",
    "        \n",
    "        # Calculate combined scores\n",
    "        for title in combined_scores:\n",
    "            combined_scores[title]['hybrid_score'] = (\n",
    "                combined_scores[title]['content_score'] + \n",
    "                combined_scores[title]['popularity_score']\n",
    "            )\n",
    "        \n",
    "        # Sort by hybrid score\n",
    "        sorted_recs = sorted(combined_scores.values(), \n",
    "                           key=lambda x: x['hybrid_score'], reverse=True)\n",
    "        \n",
    "        # Filter out movies with zero hybrid score\n",
    "        filtered_recs = [rec for rec in sorted_recs if rec['hybrid_score'] > 0]\n",
    "        \n",
    "        return filtered_recs[:n_recommendations]\n",
    "\n",
    "# Initialize hybrid recommender\n",
    "print(\"=\"*60)\n",
    "print(\"BUILDING HYBRID RECOMMENDATION SYSTEM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "hybrid_recommender = HybridRecommender(content_recommender, collab_recommender, movies_enhanced)\n",
    "print(\"Hybrid recommender initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Method Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE COMPARISON OF RECOMMENDATION METHODS\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "MOVIE-BASED RECOMMENDATIONS FOR: Toy Story\n",
      "==================================================\n",
      "\n",
      "1. CONTENT-BASED FILTERING\n",
      "------------------------------\n",
      "1. Toy Story 3 (2010) - Rating: 7.6\n",
      "   Similarity: 0.492 | Genres: Animation, Family\n",
      "2. Toy Story 2 (1999) - Rating: 7.3\n",
      "   Similarity: 0.478 | Genres: Animation, Comedy\n",
      "3. Small Fry (2011) - Rating: 6.8\n",
      "   Similarity: 0.321 | Genres: Animation, Family\n",
      "\n",
      "2. COLLABORATIVE FILTERING\n",
      "------------------------------\n",
      "Movie 'Toy Story' not found in ratings data\n",
      "\n",
      "3. HYBRID APPROACH\n",
      "------------------------------\n",
      "Getting hybrid recommendations for 'Toy Story'\n",
      "Weights: Content-based=0.6, Collaborative=0.4\n",
      "Collaborative filtering failed, using content-based only\n",
      "1. Toy Story 3 (2010) - Rating: 7.6\n",
      "   Hybrid Score: 0.492 | Genres: Animation, Family\n",
      "2. Toy Story 2 (1999) - Rating: 7.3\n",
      "   Hybrid Score: 0.478 | Genres: Animation, Comedy\n",
      "3. Small Fry (2011) - Rating: 6.8\n",
      "   Hybrid Score: 0.321 | Genres: Animation, Family\n",
      "\n",
      "\n",
      "============================================================\n",
      "QUERY-BASED RECOMMENDATIONS COMPARISON\n",
      "============================================================\n",
      "\n",
      "\n",
      "🔍 Query: 'horror movie suitable for teenagers'\n",
      "==================================================\n",
      "\n",
      "1. ORIGINAL SEARCH\n",
      "--------------------\n",
      "1. Dracula: Dead and Loving It (1995-12-22) - Rating: 5.7\n",
      "2. From Dusk Till Dawn (1996-01-19) - Rating: 6.9\n",
      "3. Screamers (1995-09-08) - Rating: 6.1\n",
      "\n",
      "2. CONTENT-BASED FILTERING\n",
      "-------------------------\n",
      "Getting content-based recommendations for query: 'horror movie suitable for teenagers'\n",
      "1. Diary of the Dead (2007) - Rating: 5.4\n",
      "   Similarity: 0.365\n",
      "2. Anguish (1987) - Rating: 6.6\n",
      "   Similarity: 0.331\n",
      "3. Madhouse (1974) - Rating: 6.0\n",
      "   Similarity: 0.322\n",
      "\n",
      "3. HYBRID APPROACH\n",
      "------------------\n",
      "Getting hybrid recommendations for query: 'horror movie suitable for teenagers'\n",
      "Getting content-based recommendations for query: 'horror movie suitable for teenagers'\n",
      "1. Diary of the Dead (2007) - Rating: 5.4\n",
      "   Hybrid Score: 0.256\n",
      "2. Anguish (1987) - Rating: 6.6\n",
      "   Hybrid Score: 0.231\n",
      "3. Madhouse (1974) - Rating: 6.0\n",
      "   Hybrid Score: 0.225\n",
      "\n",
      "\n",
      "🔍 Query: 'action adventure movie'\n",
      "==================================================\n",
      "\n",
      "1. ORIGINAL SEARCH\n",
      "--------------------\n",
      "1. Heat (1995-12-15) - Rating: 7.7\n",
      "2. Tom and Huck (1995-12-22) - Rating: 5.4\n",
      "3. Sudden Death (1995-12-22) - Rating: 5.5\n",
      "\n",
      "2. CONTENT-BASED FILTERING\n",
      "-------------------------\n",
      "Getting content-based recommendations for query: 'action adventure movie'\n",
      "1. Alex L'ariete (2000) - Rating: 2.3\n",
      "   Similarity: 0.499\n",
      "2. Disaster Movie (2008) - Rating: 3.1\n",
      "   Similarity: 0.441\n",
      "3. Silver Medalist (2009) - Rating: 7.4\n",
      "   Similarity: 0.411\n",
      "\n",
      "3. HYBRID APPROACH\n",
      "------------------\n",
      "Getting hybrid recommendations for query: 'action adventure movie'\n",
      "Getting content-based recommendations for query: 'action adventure movie'\n",
      "1. Alex L'ariete (2000) - Rating: 2.3\n",
      "   Hybrid Score: 0.349\n",
      "2. Disaster Movie (2008) - Rating: 3.1\n",
      "   Hybrid Score: 0.309\n",
      "3. Silver Medalist (2009) - Rating: 7.4\n",
      "   Hybrid Score: 0.288\n",
      "\n",
      "\n",
      "🔍 Query: 'romantic comedy'\n",
      "==================================================\n",
      "\n",
      "1. ORIGINAL SEARCH\n",
      "--------------------\n",
      "1. Toy Story (1995-10-30) - Rating: 7.7\n",
      "2. Grumpier Old Men (1995-12-22) - Rating: 6.5\n",
      "3. Waiting to Exhale (1995-12-22) - Rating: 6.1\n",
      "\n",
      "2. CONTENT-BASED FILTERING\n",
      "-------------------------\n",
      "Getting content-based recommendations for query: 'romantic comedy'\n",
      "1. Sex, Love & Therapy (2014) - Rating: 4.9\n",
      "   Similarity: 0.536\n",
      "2. Letters to Santa (2011) - Rating: 7.1\n",
      "   Similarity: 0.445\n",
      "3. Tired of Kissing Frogs (2006) - Rating: 6.2\n",
      "   Similarity: 0.440\n",
      "\n",
      "3. HYBRID APPROACH\n",
      "------------------\n",
      "Getting hybrid recommendations for query: 'romantic comedy'\n",
      "Getting content-based recommendations for query: 'romantic comedy'\n",
      "1. Sex, Love & Therapy (2014) - Rating: 4.9\n",
      "   Hybrid Score: 0.375\n",
      "2. Letters to Santa (2011) - Rating: 7.1\n",
      "   Hybrid Score: 0.311\n",
      "3. Tired of Kissing Frogs (2006) - Rating: 6.2\n",
      "   Hybrid Score: 0.308\n",
      "\n",
      "\n",
      "🔍 Query: 'war military movie'\n",
      "==================================================\n",
      "\n",
      "1. ORIGINAL SEARCH\n",
      "--------------------\n",
      "No results found\n",
      "\n",
      "2. CONTENT-BASED FILTERING\n",
      "-------------------------\n",
      "Getting content-based recommendations for query: 'war military movie'\n",
      "1. Kamchatka (2002) - Rating: 6.3\n",
      "   Similarity: 0.494\n",
      "2. Disaster Movie (2008) - Rating: 3.1\n",
      "   Similarity: 0.390\n",
      "3. Never So Few (1959) - Rating: 6.1\n",
      "   Similarity: 0.313\n",
      "\n",
      "3. HYBRID APPROACH\n",
      "------------------\n",
      "Getting hybrid recommendations for query: 'war military movie'\n",
      "Getting content-based recommendations for query: 'war military movie'\n",
      "1. Kamchatka (2002) - Rating: 6.3\n",
      "   Hybrid Score: 0.346\n",
      "2. Disaster Movie (2008) - Rating: 3.1\n",
      "   Hybrid Score: 0.273\n",
      "3. Never So Few (1959) - Rating: 6.1\n",
      "   Hybrid Score: 0.219\n",
      "\n",
      "\n",
      "🔍 Query: 'animated family movie'\n",
      "==================================================\n",
      "\n",
      "1. ORIGINAL SEARCH\n",
      "--------------------\n",
      "No results found\n",
      "\n",
      "2. CONTENT-BASED FILTERING\n",
      "-------------------------\n",
      "Getting content-based recommendations for query: 'animated family movie'\n",
      "1. Disaster Movie (2008) - Rating: 3.1\n",
      "   Similarity: 0.379\n",
      "2. Turtles Forever (2009) - Rating: 5.8\n",
      "   Similarity: 0.353\n",
      "3. Adventures of Mowgli (1973) - Rating: 5.7\n",
      "   Similarity: 0.345\n",
      "\n",
      "3. HYBRID APPROACH\n",
      "------------------\n",
      "Getting hybrid recommendations for query: 'animated family movie'\n",
      "Getting content-based recommendations for query: 'animated family movie'\n",
      "1. Disaster Movie (2008) - Rating: 3.1\n",
      "   Hybrid Score: 0.265\n",
      "2. Turtles Forever (2009) - Rating: 5.8\n",
      "   Hybrid Score: 0.247\n",
      "3. Adventures of Mowgli (1973) - Rating: 5.7\n",
      "   Hybrid Score: 0.241\n",
      "\n",
      "\n",
      "==================================================\n",
      "ANALYSIS SUMMARY\n",
      "==================================================\n",
      "Successfully implemented:\n",
      "1. Content-Based Filtering using TF-IDF on movie features\n",
      "2. Collaborative Filtering using SVD matrix factorization\n",
      "3. Hybrid approach combining both methods\n",
      "4. Comparison with original keyword-based search\n",
      "\n",
      "Key Improvements over original search:\n",
      "- Semantic understanding of queries (not just keywords)\n",
      "- Consideration of cast, director, plot, and keywords\n",
      "- User preference patterns from collaborative filtering\n",
      "- Robust hybrid scoring combining multiple signals\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive comparison of all methods\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE COMPARISON OF RECOMMENDATION METHODS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_queries = [\n",
    "    \"horror movie suitable for teenagers\",\n",
    "    \"action adventure movie\", \n",
    "    \"romantic comedy\",\n",
    "    \"war military movie\",\n",
    "    \"animated family movie\"\n",
    "]\n",
    "\n",
    "test_movie = \"Toy Story\"\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"MOVIE-BASED RECOMMENDATIONS FOR: {test_movie}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Content-based recommendations\n",
    "print(\"\\n1. CONTENT-BASED FILTERING\")\n",
    "print(\"-\" * 30)\n",
    "content_recs = content_recommender.get_recommendations(test_movie, 3)\n",
    "if isinstance(content_recs, str):\n",
    "    print(content_recs)\n",
    "else:\n",
    "    for i, rec in enumerate(content_recs, 1):\n",
    "        print(f\"{i}. {rec['title']} ({rec['year']}) - Rating: {rec['rating']:.1f}\")\n",
    "        print(f\"   Similarity: {rec['similarity_score']:.3f} | Genres: {', '.join(rec['genres'][:2])}\")\n",
    "\n",
    "# Collaborative filtering recommendations  \n",
    "print(\"\\n2. COLLABORATIVE FILTERING\")\n",
    "print(\"-\" * 30)\n",
    "collab_recs = collab_recommender.get_movie_recommendations_by_title(test_movie, 3)\n",
    "if isinstance(collab_recs, str):\n",
    "    print(collab_recs)\n",
    "else:\n",
    "    for i, rec in enumerate(collab_recs, 1):\n",
    "        print(f\"{i}. {rec['title']} ({rec['year']}) - Avg Rating: {rec['avg_rating']:.1f}\")\n",
    "        print(f\"   Similarity: {rec['similarity_score']:.3f} | Genres: {', '.join(rec['genres'][:2])}\")\n",
    "\n",
    "# Hybrid recommendations\n",
    "print(\"\\n3. HYBRID APPROACH\")\n",
    "print(\"-\" * 30)\n",
    "hybrid_recs = hybrid_recommender.get_hybrid_recommendations(test_movie, 3)\n",
    "if isinstance(hybrid_recs, str):\n",
    "    print(hybrid_recs)\n",
    "else:\n",
    "    for i, rec in enumerate(hybrid_recs, 1):\n",
    "        print(f\"{i}. {rec['title']} ({rec['year']}) - Rating: {rec['rating']:.1f}\")\n",
    "        # Handle missing hybrid_score key\n",
    "        score_key = 'hybrid_score' if 'hybrid_score' in rec else 'similarity_score'\n",
    "        score_value = rec.get(score_key, 0)\n",
    "        print(f\"   Hybrid Score: {score_value:.3f} | Genres: {', '.join(rec['genres'][:2])}\")\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"QUERY-BASED RECOMMENDATIONS COMPARISON\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n\\n🔍 Query: '{query}'\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Original search\n",
    "    print(\"\\n1. ORIGINAL SEARCH\")\n",
    "    print(\"-\" * 20)\n",
    "    original_results = search_movies(query, movies_enhanced)\n",
    "    if original_results.get('results'):\n",
    "        top_3 = original_results['results'][:3]\n",
    "        for i, movie in enumerate(top_3, 1):\n",
    "            release_date = movie['release_date'][:10] if movie['release_date'] != 'NaT' else 'Unknown'\n",
    "            print(f\"{i}. {movie['title']} ({release_date}) - Rating: {movie['rating']}\")\n",
    "    else:\n",
    "        print(\"No results found\")\n",
    "    \n",
    "    # Content-based\n",
    "    print(\"\\n2. CONTENT-BASED FILTERING\")\n",
    "    print(\"-\" * 25)\n",
    "    try:\n",
    "        content_query_recs = content_recommender.get_recommendations_by_query(query, 3)\n",
    "        if content_query_recs:\n",
    "            for i, rec in enumerate(content_query_recs, 1):\n",
    "                print(f\"{i}. {rec['title']} ({rec['year']}) - Rating: {rec['rating']:.1f}\")\n",
    "                print(f\"   Similarity: {rec['similarity_score']:.3f}\")\n",
    "        else:\n",
    "            print(\"No results found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in content-based filtering: {e}\")\n",
    "    \n",
    "    # Hybrid approach\n",
    "    print(\"\\n3. HYBRID APPROACH\")\n",
    "    print(\"-\" * 18)\n",
    "    try:\n",
    "        hybrid_query_recs = hybrid_recommender.get_hybrid_query_recommendations(query, 3)\n",
    "        if hybrid_query_recs:\n",
    "            for i, rec in enumerate(hybrid_query_recs, 1):\n",
    "                print(f\"{i}. {rec['title']} ({rec['year']}) - Rating: {rec['rating']:.1f}\")\n",
    "                # Handle missing hybrid_score key\n",
    "                score_value = rec.get('hybrid_score', rec.get('similarity_score', 0))\n",
    "                print(f\"   Hybrid Score: {score_value:.3f}\")\n",
    "        else:\n",
    "            print(\"No results found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in hybrid approach: {e}\")\n",
    "        \n",
    "print(f\"\\n\\n{'='*50}\")\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"Successfully implemented:\")\n",
    "print(\"1. Content-Based Filtering using TF-IDF on movie features\")\n",
    "print(\"2. Collaborative Filtering using SVD matrix factorization\")  \n",
    "print(\"3. Hybrid approach combining both methods\")\n",
    "print(\"4. Comparison with original keyword-based search\")\n",
    "print(\"\\nKey Improvements over original search:\")\n",
    "print(\"- Semantic understanding of queries (not just keywords)\")\n",
    "print(\"- Consideration of cast, director, plot, and keywords\")\n",
    "print(\"- User preference patterns from collaborative filtering\")\n",
    "print(\"- Robust hybrid scoring combining multiple signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion and Recommendations\n",
    "\n",
    "### Summary of Implementation\n",
    "\n",
    "This notebook successfully implemented and compared four different movie recommendation approaches:\n",
    "\n",
    "1. **Original Search**: Simple keyword-based genre filtering\n",
    "2. **Content-Based Filtering**: TF-IDF vectorization of movie features (genres, overview, keywords, cast, director) \n",
    "3. **Collaborative Filtering**: SVD matrix factorization on user ratings data\n",
    "4. **Hybrid System**: Weighted combination of content-based and collaborative filtering\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- **Content-based filtering** provides the most versatile search experience, understanding semantic queries\n",
    "- **Collaborative filtering** excels at finding movies with similar user preferences but has cold start issues\n",
    "- **Hybrid approach** offers the best balance by combining strengths of both methods\n",
    "- **Enhanced search** provides a backwards-compatible upgrade to the existing system\n",
    "\n",
    "### Implementation Recommendations\n",
    "\n",
    "1. **For Production**: Use the hybrid system as it provides the most robust recommendations\n",
    "2. **For Backwards Compatibility**: Implement enhanced search to improve existing functionality\n",
    "3. **For New Features**: Content-based filtering enables semantic search capabilities\n",
    "4. **For User Personalization**: Collaborative filtering when user interaction data is available\n",
    "\n",
    "The hybrid recommendation system successfully addresses the limitations of the original search while providing more relevant and diverse movie recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Netflix Assignment Evaluation - Test Cases from README\n",
    "\n",
    "This section specifically evaluates the failing queries mentioned in the Netflix assignment README to demonstrate quantitative improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting content-based recommendations for query: 'A horror movie suitable for teenagers in the 12-15 age range'\n",
      "Getting hybrid recommendations for query: 'A horror movie suitable for teenagers in the 12-15 age range'\n",
      "Getting content-based recommendations for query: 'A horror movie suitable for teenagers in the 12-15 age range'\n",
      "Query: A horror movie suitable for teenagers in the 12-15 age range\n",
      "  Original: 3250 results\n",
      "  Content:  5 results\n",
      "  Hybrid:   5 results\n",
      "\n",
      "Getting content-based recommendations for query: 'A spooky movie suitable for teenagers in the 12-15 age range'\n",
      "Getting hybrid recommendations for query: 'A spooky movie suitable for teenagers in the 12-15 age range'\n",
      "Getting content-based recommendations for query: 'A spooky movie suitable for teenagers in the 12-15 age range'\n",
      "Query: A spooky movie suitable for teenagers in the 12-15 age range\n",
      "  Original: 0 results\n",
      "  Content:  5 results\n",
      "  Hybrid:   5 results\n",
      "\n",
      "Getting content-based recommendations for query: 'War commandos'\n",
      "Getting hybrid recommendations for query: 'War commandos'\n",
      "Getting content-based recommendations for query: 'War commandos'\n",
      "Query: War commandos\n",
      "  Original: 0 results\n",
      "  Content:  5 results\n",
      "  Hybrid:   5 results\n",
      "\n",
      "Getting content-based recommendations for query: 'scary movie for teens'\n",
      "Getting hybrid recommendations for query: 'scary movie for teens'\n",
      "Getting content-based recommendations for query: 'scary movie for teens'\n",
      "Query: scary movie for teens\n",
      "  Original: 0 results\n",
      "  Content:  5 results\n",
      "  Hybrid:   5 results\n",
      "\n",
      "Getting content-based recommendations for query: 'military commandos'\n",
      "Getting hybrid recommendations for query: 'military commandos'\n",
      "Getting content-based recommendations for query: 'military commandos'\n",
      "Query: military commandos\n",
      "  Original: 0 results\n",
      "  Content:  5 results\n",
      "  Hybrid:   5 results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Netflix Assignment Test Suite\n",
    "test_queries = [\n",
    "    \"A horror movie suitable for teenagers in the 12-15 age range\",\n",
    "    \"A spooky movie suitable for teenagers in the 12-15 age range\", \n",
    "    \"War commandos\",\n",
    "    \"scary movie for teens\",\n",
    "    \"military commandos\"\n",
    "]\n",
    "\n",
    "results = {'Original Search': [], 'Content-Based': [], 'Hybrid': []}\n",
    "\n",
    "for query in test_queries:\n",
    "    original_count = len(search_movies(query, movies_enhanced).get('results', []))\n",
    "    content_count = len(content_recommender.get_recommendations_by_query(query, 5))\n",
    "    hybrid_count = len(hybrid_recommender.get_hybrid_query_recommendations(query, 5))\n",
    "    \n",
    "    results['Original Search'].append(original_count > 0)\n",
    "    results['Content-Based'].append(content_count > 0)\n",
    "    results['Hybrid'].append(hybrid_count > 0)\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"  Original: {original_count} results\")\n",
    "    print(f\"  Content:  {content_count} results\")\n",
    "    print(f\"  Hybrid:   {hybrid_count} results\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Search: 20% success rate\n",
      "Content-Based: 100% success rate\n",
      "Hybrid: 100% success rate\n",
      "\n",
      "Netflix Assignment Key Fixes:\n",
      "'A spooky movie suitable for teenagers in the 12-15 age range': FIXED\n",
      "'War commandos': FIXED\n",
      "\n",
      "Netflix README Score:\n",
      "Original: 1/3 queries working\n",
      "Content:  3/3 queries working\n",
      "Hybrid:   3/3 queries working\n"
     ]
    }
   ],
   "source": [
    "# Success Rate Analysis\n",
    "for method, result_list in results.items():\n",
    "    success_rate = sum(result_list) / len(result_list) * 100\n",
    "    print(f\"{method}: {success_rate:.0f}% success rate\")\n",
    "\n",
    "readme_failures = [\n",
    "    \"A spooky movie suitable for teenagers in the 12-15 age range\",\n",
    "    \"War commandos\"\n",
    "]\n",
    "\n",
    "print(\"\\nNetflix Assignment Key Fixes:\")\n",
    "for query in readme_failures:\n",
    "    idx = test_queries.index(query)\n",
    "    original = results['Original Search'][idx]\n",
    "    content = results['Content-Based'][idx] \n",
    "    hybrid = results['Hybrid'][idx]\n",
    "    \n",
    "    status = \"FIXED\" if not original and (content or hybrid) else \"Still failing\"\n",
    "    print(f\"'{query}': {status}\")\n",
    "\n",
    "netflix_queries = test_queries[:3]\n",
    "original_score = sum([results['Original Search'][test_queries.index(q)] for q in netflix_queries])\n",
    "content_score = sum([results['Content-Based'][test_queries.index(q)] for q in netflix_queries])\n",
    "hybrid_score = sum([results['Hybrid'][test_queries.index(q)] for q in netflix_queries])\n",
    "\n",
    "print(f\"\\nNetflix README Score:\")\n",
    "print(f\"Original: {original_score}/3 queries working\")\n",
    "print(f\"Content:  {content_score}/3 queries working\") \n",
    "print(f\"Hybrid:   {hybrid_score}/3 queries working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Enhanced Content-Based Filtering with Sentence Transformers\n",
    "\n",
    "TF-IDF treats words independently and misses semantic context. This section implements a Sentence Transformers approach that understands semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install sentence-transformers with fallback handling\ntry:\n    from sentence_transformers import SentenceTransformer\n    import torch\n    print(\"Sentence Transformers already installed\")\nexcept ImportError:\n    print(\"Installing sentence-transformers...\")\n    import subprocess\n    subprocess.run(['pip', 'install', 'sentence-transformers'], check=True)\n    from sentence_transformers import SentenceTransformer\n    import torch\n    print(\"Installation complete\")\n\nclass EnhancedContentBasedRecommender:\n    def __init__(self, movies_df):\n        self.movies_df = movies_df.copy()\n        \n        # GPU detection and configuration\n        self.device = self._setup_device()\n        print(f\"Using device: {self.device}\")\n        \n        # Initialize model with device configuration\n        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n        if self.device != 'cpu':\n            self.model = self.model.to(self.device)\n        \n        self.content_embeddings = None\n        self.movie_indices = None\n        self._prepare_content_features()\n        self._build_embedding_matrix()\n    \n    def _setup_device(self):\n        \"\"\"Detect and configure the best available device\"\"\"\n        if torch.cuda.is_available():\n            device = 'cuda'\n            gpu_name = torch.cuda.get_device_name(0)\n            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n            print(f\"GPU detected: {gpu_name} ({gpu_memory:.1f} GB)\")\n            return device\n        else:\n            print(\"No GPU detected, using CPU\")\n            return 'cpu'\n    \n    def _prepare_content_features(self):\n        \"\"\"Combine content features into text for embedding\"\"\"\n        print(\"Preparing content features for semantic embedding...\")\n        \n        def format_features(row):\n            features = []\n            if row['genres_list']: features.extend(row['genres_list'])\n            if row['keywords_list']: features.extend(row['keywords_list'][:5])\n            if row['director']: features.append(f\"directed by {row['director']}\")\n            if row['cast_list']: features.append(f\"starring {', '.join(row['cast_list'][:3])}\")\n            if row['overview']: features.append(row['overview'])\n            return ' '.join(features)\n        \n        self.movies_df['content_text'] = self.movies_df.apply(format_features, axis=1)\n        self.movie_indices = pd.Series(self.movies_df.index, index=self.movies_df['title']).to_dict()\n        print(f\"Prepared content features for {len(self.movies_df)} movies\")\n    \n    def _build_embedding_matrix(self):\n        \"\"\"Build semantic embeddings matrix with GPU optimization\"\"\"\n        print(\"Building semantic embeddings matrix...\")\n        \n        # Configure batch size based on device\n        if self.device == 'cuda':\n            batch_size = 64  # Larger batch for GPU\n            print(\"Using GPU-optimized batch processing\")\n        else:\n            batch_size = 32  # Conservative batch for CPU\n            print(\"Using CPU batch processing\")\n        \n        texts = self.movies_df['content_text'].tolist()\n        \n        # Add timing and memory monitoring\n        import time\n        start_time = time.time()\n        \n        if self.device == 'cuda':\n            # Monitor GPU memory\n            torch.cuda.empty_cache()\n            initial_memory = torch.cuda.memory_allocated()\n            \n        self.content_embeddings = self.model.encode(\n            texts, \n            batch_size=batch_size,\n            show_progress_bar=True,\n            device=self.device\n        )\n        \n        encoding_time = time.time() - start_time\n        \n        if self.device == 'cuda':\n            peak_memory = torch.cuda.max_memory_allocated()\n            memory_used = (peak_memory - initial_memory) / 1e9\n            print(f\"GPU memory used: {memory_used:.2f} GB\")\n            torch.cuda.empty_cache()\n        \n        print(f\"Embedding matrix shape: {self.content_embeddings.shape}\")\n        print(f\"Encoding completed in {encoding_time:.2f}s ({encoding_time/len(texts)*1000:.1f}ms per text)\")\n    \n    def get_recommendations(self, movie_title, n_recommendations=10):\n        \"\"\"Get semantic content-based recommendations\"\"\"\n        if movie_title not in self.movie_indices:\n            return f\"Movie '{movie_title}' not found in database\"\n        \n        movie_idx = self.movie_indices[movie_title]\n        movie_embedding = self.content_embeddings[movie_idx].reshape(1, -1)\n        \n        # Calculate cosine similarity\n        similarities = cosine_similarity(movie_embedding, self.content_embeddings).flatten()\n        similar_indices = similarities.argsort()[::-1][1:n_recommendations+1]\n        \n        recommendations = []\n        for idx in similar_indices:\n            movie = self.movies_df.iloc[idx]\n            recommendations.append({\n                'title': movie['title'],\n                'genres': movie['genres_list'],\n                'rating': movie['vote_average'],\n                'year': int(movie['release_year']) if pd.notna(movie['release_year']) else 'Unknown',\n                'similarity_score': similarities[idx],\n                'director': movie['director']\n            })\n        \n        return recommendations\n    \n    def get_recommendations_by_query(self, query, n_recommendations=10):\n        \"\"\"Get semantic recommendations for text query\"\"\"\n        print(f\"Getting semantic recommendations for: '{query}'\")\n        \n        # Encode query into same semantic space\n        query_embedding = self.model.encode([query], device=self.device)\n        similarities = cosine_similarity(query_embedding, self.content_embeddings).flatten()\n        similar_indices = similarities.argsort()[::-1][:n_recommendations]\n        \n        recommendations = []\n        for idx in similar_indices:\n            if similarities[idx] > 0:\n                movie = self.movies_df.iloc[idx]\n                recommendations.append({\n                    'title': movie['title'],\n                    'genres': movie['genres_list'],\n                    'rating': movie['vote_average'],\n                    'year': int(movie['release_year']) if pd.notna(movie['release_year']) else 'Unknown',\n                    'similarity_score': similarities[idx],\n                    'director': movie['director']\n                })\n        \n        return recommendations\n\nprint(\"Creating Enhanced Content-Based Recommender with GPU support...\")\nenhanced_recommender = EnhancedContentBasedRecommender(movies_enhanced)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct TF-IDF vs Sentence Transformers Comparison\n",
    "import time\n",
    "\n",
    "comparison_queries = [\n",
    "    \"A spooky movie suitable for teenagers\",\n",
    "    \"War commandos\", \n",
    "    \"scary horror film\",\n",
    "    \"military soldiers movie\",\n",
    "    \"romantic comedy\"\n",
    "]\n",
    "\n",
    "print(\"TF-IDF vs Sentence Transformers Comparison\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for query in comparison_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # TF-IDF approach\n",
    "    start_time = time.time()\n",
    "    tfidf_results = content_recommender.get_recommendations_by_query(query, 3)\n",
    "    tfidf_time = time.time() - start_time\n",
    "    \n",
    "    # Sentence Transformers approach  \n",
    "    start_time = time.time()\n",
    "    semantic_results = enhanced_recommender.get_recommendations_by_query(query, 3)\n",
    "    semantic_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"TF-IDF Results ({tfidf_time:.3f}s):\")\n",
    "    for i, rec in enumerate(tfidf_results, 1):\n",
    "        print(f\"  {i}. {rec['title']} ({rec['year']}) - Score: {rec['similarity_score']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nSentence Transformers Results ({semantic_time:.3f}s):\")\n",
    "    for i, rec in enumerate(semantic_results, 1):\n",
    "        print(f\"  {i}. {rec['title']} ({rec['year']}) - Score: {rec['similarity_score']:.3f}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Understanding Analysis\n",
    "print(\"Semantic Understanding Test\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Test semantic similarity between related terms\n",
    "semantic_tests = [\n",
    "    [\"spooky movie\", \"scary movie\", \"frightening film\"],\n",
    "    [\"war commandos\", \"military soldiers\", \"combat troops\"], \n",
    "    [\"teenage horror\", \"horror for teenagers\", \"teen scary movie\"],\n",
    "    [\"romantic comedy\", \"rom-com\", \"funny love story\"]\n",
    "]\n",
    "\n",
    "for test_group in semantic_tests:\n",
    "    print(f\"\\nTesting semantic similarity: {test_group}\")\n",
    "    \n",
    "    # Get embeddings for each term\n",
    "    embeddings = enhanced_recommender.model.encode(test_group)\n",
    "    \n",
    "    # Calculate pairwise similarities\n",
    "    similarities = cosine_similarity(embeddings)\n",
    "    \n",
    "    for i, term1 in enumerate(test_group):\n",
    "        for j, term2 in enumerate(test_group):\n",
    "            if i < j:  # Only show upper triangle\n",
    "                sim_score = similarities[i][j]\n",
    "                print(f\"  '{term1}' vs '{term2}': {sim_score:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Netflix Assignment Evaluation with Sentence Transformers\n",
    "netflix_queries = [\n",
    "    \"A horror movie suitable for teenagers in the 12-15 age range\",\n",
    "    \"A spooky movie suitable for teenagers in the 12-15 age range\",\n",
    "    \"War commandos\"\n",
    "]\n",
    "\n",
    "print(\"Netflix Assignment: TF-IDF vs Sentence Transformers\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "methods = {\n",
    "    'Original Search': lambda q: len(search_movies(q, movies_enhanced).get('results', [])),\n",
    "    'TF-IDF Content': lambda q: len(content_recommender.get_recommendations_by_query(q, 5)),\n",
    "    'Sentence Transformers': lambda q: len(enhanced_recommender.get_recommendations_by_query(q, 5))\n",
    "}\n",
    "\n",
    "results = {method: [] for method in methods}\n",
    "\n",
    "for query in netflix_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    \n",
    "    for method_name, method_func in methods.items():\n",
    "        count = method_func(query)\n",
    "        results[method_name].append(count > 0)\n",
    "        print(f\"  {method_name}: {count} results\")\n",
    "\n",
    "print(f\"\\nFinal Netflix Assignment Scores:\")\n",
    "for method_name, result_list in results.items():\n",
    "    success_rate = sum(result_list) / len(result_list) * 100\n",
    "    working_queries = sum(result_list)\n",
    "    print(f\"{method_name}: {working_queries}/3 queries working ({success_rate:.0f}%)\")\n",
    "\n",
    "print(f\"\\nRecommendation for Netflix:\")\n",
    "if results['Sentence Transformers'][1] and results['Sentence Transformers'][2]:  # spooky & war queries\n",
    "    print(\"Use Sentence Transformers - solves semantic context issues\")\n",
    "else:\n",
    "    print(\"TF-IDF sufficient for basic keyword matching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class SemanticHybridRecommender:\n    def __init__(self, semantic_recommender, collab_recommender, movies_df):\n        self.semantic_recommender = semantic_recommender\n        self.collab_recommender = collab_recommender\n        self.movies_df = movies_df\n        print(\"Semantic Hybrid Recommender initialized with GPU-optimized Sentence Transformers!\")\n        \n    def get_hybrid_recommendations(self, movie_title, n_recommendations=10, \n                                 semantic_weight=0.6, collab_weight=0.4):\n        \"\"\"Get hybrid recommendations combining semantic content-based and collaborative filtering\"\"\"\n        print(f\"Getting semantic hybrid recommendations for '{movie_title}'\")\n        print(f\"Weights: Semantic={semantic_weight}, Collaborative={collab_weight}\")\n        \n        # Get recommendations from both methods\n        semantic_recs = self.semantic_recommender.get_recommendations(movie_title, n_recommendations*2)\n        collab_recs = self.collab_recommender.get_movie_recommendations_by_title(movie_title, n_recommendations*2)\n        \n        if isinstance(semantic_recs, str) or isinstance(collab_recs, str):\n            # If one method fails, use the other\n            if isinstance(semantic_recs, str) and not isinstance(collab_recs, str):\n                print(\"Semantic content-based failed, using collaborative filtering only\")\n                return collab_recs[:n_recommendations]\n            elif isinstance(collab_recs, str) and not isinstance(semantic_recs, str):\n                print(\"Collaborative filtering failed, using semantic content-based only\")\n                return semantic_recs[:n_recommendations]\n            else:\n                return f\"Both methods failed for movie '{movie_title}'\"\n        \n        # Create a dictionary to combine scores\n        combined_scores = {}\n        \n        # Add semantic content-based recommendations\n        for rec in semantic_recs:\n            title = rec['title']\n            combined_scores[title] = {\n                'title': title,\n                'semantic_score': rec['similarity_score'] * semantic_weight,\n                'collab_score': 0,\n                'genres': rec['genres'],\n                'rating': rec['rating'],\n                'year': rec['year'],\n                'director': rec.get('director', '')\n            }\n        \n        # Add collaborative filtering recommendations\n        for rec in collab_recs:\n            title = rec['title']\n            if title in combined_scores:\n                combined_scores[title]['collab_score'] = rec['similarity_score'] * collab_weight\n            else:\n                combined_scores[title] = {\n                    'title': title,\n                    'semantic_score': 0,\n                    'collab_score': rec['similarity_score'] * collab_weight,\n                    'genres': rec['genres'],\n                    'rating': rec['avg_rating'],\n                    'year': rec['year'],\n                    'director': ''\n                }\n        \n        # Calculate combined scores\n        for title in combined_scores:\n            combined_scores[title]['hybrid_score'] = (\n                combined_scores[title]['semantic_score'] + \n                combined_scores[title]['collab_score']\n            )\n        \n        # Sort by hybrid score\n        sorted_recs = sorted(combined_scores.values(), \n                           key=lambda x: x['hybrid_score'], reverse=True)\n        \n        return sorted_recs[:n_recommendations]\n    \n    def get_hybrid_query_recommendations(self, query, n_recommendations=10):\n        \"\"\"Get hybrid recommendations for a text query using semantic understanding\"\"\"\n        print(f\"Getting semantic hybrid recommendations for query: '{query}'\")\n        print(f\"Using GPU-accelerated semantic processing on device: {self.semantic_recommender.device}\")\n        \n        # Get semantic content-based recommendations for the query\n        semantic_recs = self.semantic_recommender.get_recommendations_by_query(query, n_recommendations*2)\n        \n        # Get popular movies as baseline from collaborative filtering\n        popular_recs = self.collab_recommender.get_popular_movies(n_recommendations*2)\n        \n        # Combine recommendations with semantic having higher weight for queries (better context understanding)\n        combined_scores = {}\n        \n        # Add semantic content-based recommendations (75% weight for better semantic understanding)\n        for rec in semantic_recs:\n            title = rec['title']\n            combined_scores[title] = {\n                'title': title,\n                'semantic_score': rec['similarity_score'] * 0.75,\n                'popularity_score': 0,\n                'genres': rec['genres'],\n                'rating': rec['rating'],\n                'year': rec['year'],\n                'director': rec.get('director', '')\n            }\n        \n        # Add popularity scores (25% weight)\n        for rec in popular_recs:\n            title = rec['title']\n            norm_popularity = min(rec['popularity_score'] / 100, 1.0)\n            \n            if title in combined_scores:\n                combined_scores[title]['popularity_score'] = norm_popularity * 0.25\n            else:\n                combined_scores[title] = {\n                    'title': title,\n                    'semantic_score': 0,\n                    'popularity_score': norm_popularity * 0.25,\n                    'genres': rec['genres'],\n                    'rating': rec['avg_rating'],\n                    'year': rec['year'],\n                    'director': ''\n                }\n        \n        # Calculate combined scores\n        for title in combined_scores:\n            combined_scores[title]['hybrid_score'] = (\n                combined_scores[title]['semantic_score'] + \n                combined_scores[title]['popularity_score']\n            )\n        \n        # Sort by hybrid score\n        sorted_recs = sorted(combined_scores.values(), \n                           key=lambda x: x['hybrid_score'], reverse=True)\n        \n        # Filter out movies with zero hybrid score\n        filtered_recs = [rec for rec in sorted_recs if rec['hybrid_score'] > 0]\n        \n        return filtered_recs[:n_recommendations]\n\n# Initialize semantic hybrid recommender\nprint(\"=\"*60)\nprint(\"BUILDING SEMANTIC HYBRID RECOMMENDATION SYSTEM\")\nprint(\"=\"*60)\n\nsemantic_hybrid_recommender = SemanticHybridRecommender(\n    enhanced_recommender, \n    collab_recommender, \n    movies_enhanced\n)\n\n# Test the semantic hybrid system\nprint(\"\\nTesting Semantic Hybrid Recommendations\")\nprint(\"=\"*45)\n\n# Test with movie-based recommendations\ntest_movie = \"Toy Story\"\nprint(f\"\\nSemantic Hybrid recommendations for '{test_movie}':\")\nprint(\"-\" * 45)\nsemantic_hybrid_recs = semantic_hybrid_recommender.get_hybrid_recommendations(test_movie, 5)\nif isinstance(semantic_hybrid_recs, str):\n    print(semantic_hybrid_recs)\nelse:\n    for i, rec in enumerate(semantic_hybrid_recs, 1):\n        print(f\"{i}. {rec['title']} ({rec['year']}) - Rating: {rec['rating']:.1f}\")\n        score_value = rec.get('hybrid_score', 0)\n        print(f\"   Hybrid Score: {score_value:.3f} | Genres: {', '.join(rec['genres'][:2])}\")\n\n# Test with query-based recommendations for Netflix failing queries\nnetflix_test_queries = [\n    \"A spooky movie suitable for teenagers in the 12-15 age range\",\n    \"War commandos\"\n]\n\nfor query in netflix_test_queries:\n    print(f\"\\nSemantic Hybrid results for: '{query}'\")\n    print(\"-\" * 50)\n    semantic_hybrid_results = semantic_hybrid_recommender.get_hybrid_query_recommendations(query, 3)\n    if semantic_hybrid_results:\n        for i, rec in enumerate(semantic_hybrid_results, 1):\n            print(f\"{i}. {rec['title']} ({rec['year']}) - Rating: {rec['rating']:.1f}\")\n            print(f\"   Hybrid Score: {rec['hybrid_score']:.3f}\")\n    else:\n        print(\"No recommendations found\")\n    print()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}